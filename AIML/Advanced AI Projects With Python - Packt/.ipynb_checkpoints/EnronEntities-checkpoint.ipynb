{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbox = mailbox.mbox('enron.mbox')\n",
    "msgs=mbox.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg_key in msgs[10:20]:\n",
    "    message = mbox.get(msg_key)\n",
    "    print(msg_key,message['Subject'],message['From'],message['Date'],sep = \" / \")\n",
    "    print(\"======================\")\n",
    "    print(message.get_payload())\n",
    "    print(\"**********************************\")\n",
    "    print(\"**********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanup_email(msgbody):\n",
    "    regex_replies = re.compile('(\\-+Original Message|\\-\\-+|~~+).*', re.DOTALL) # find 'Original Message...' and variants\n",
    "    msgbody = re.sub(regex_replies, '', msgbody)\n",
    "    msgbody = re.sub(r'=\\d\\d', ' ', msgbody) # remove funny email formatting issues\n",
    "    msgbody = re.sub(r'\\s*>.*', '', msgbody) # remove quotes\n",
    "    msgbody = re.sub(r'https?://.*?\\s', '', msgbody) # remove links\n",
    "    bigspace = re.compile(r'\\n\\n\\n\\n\\n+.*', re.DOTALL) # find large gaps\n",
    "    msgbody = re.sub(bigspace, '', msgbody)\n",
    "    bigindent = re.compile(r'(\\t| {4,}).*', re.DOTALL) # find big indentations (i.e., a quoted document)\n",
    "    msgbody = re.sub(bigindent, '', msgbody)\n",
    "    emailpaste = re.compile(r'(From|Subject|To): .*', re.DOTALL) # find pasted emails\n",
    "    msgbody = re.sub(emailpaste, '', msgbody)\n",
    "    msgbody = re.sub(r'=(\\s*)\\n', '\\1', msgbody) # fix broken newlines\n",
    "    msgbody = re.sub(r' ,([stm])', '\\'\\1', msgbody) # fix funny apostrophe 's and 't and 'm\n",
    "    msgbody = re.sub(r'([\\?\\.])\\?', '\\1', msgbody) # fix funny extra question marks\n",
    "    msgbody = re.sub(r'\\x01', ' ', msgbody) # fix odd spaces\n",
    "    return msgbody.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg_key in msgs[326:500]:\n",
    "    message = mbox.get(msg_key)\n",
    "    msgbody = cleanup_email(message.get_payload())\n",
    "    print(msg_key, message['Subject'], message['From'],message['To'], message['Date'],sep=\" / \")\n",
    "    print(\"============\")\n",
    "    print(msgbody)\n",
    "    print(\"*****\")\n",
    "    print(\"********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_good_tofrom(msg):\n",
    "    return (re.match(r'.*(admin|newsletter|list|announce|all[\\._]|everyone[\\.\\_]).*',msg['From'],re.IGNORECASE) is None and\n",
    "    msg['To'] is not None and\n",
    "    re.match(r'.*(admin|newsletter|list|announce|all[\\._]|everyone[\\.\\_]).*',msg['To'],re.IGNORECASE) is None and\n",
    "    re.match(r'.*@enron\\.com',msg['From'],re.IGNORECASE) and\n",
    "    len(msg['To'].split())<=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg_key in msgs[15000:15500]:\n",
    "    message = mbox.get(msg_key)\n",
    "    if check_good_tofrom(message):\n",
    "        msgbody = cleanup_email(message.get_payload())\n",
    "        if len(msgbody)>0:\n",
    "                print(msg_key, message['Subject'], message['From'],message['To'], message['Date'],sep=\" / \")\n",
    "                print(\"============\")\n",
    "                print(msgbody)\n",
    "                print(\"*****\")\n",
    "                print(\"********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in nlp(u\"I want to buy stock.\"):\n",
    "    print(token.text,token.lemma_,token.pos_,token.tag_,token.is_alpha,token.is_stop,sep = \" / \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in nlp(\"Bob says he knows about the scam\"):\n",
    "    print(token.text,token.lemma_,token.pos_,token.tag_,token.is_alpha,token.is_stop,sep = \" / \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(\"I want to buy stock.\"),style = \"dep\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(\"I want to buy stock.\"),style = \"dep\",jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(\"I want to buy stock.\"),style = \"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(\"Bob said he knows about the scam.\"),style = \"dep\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import nsubj, xcomp, dobj, pobj, prep, attr,VERB, PRON, NOUN,PROPN, PUNCT\n",
    "def extract_relationships(doc):\n",
    "    relationships = []\n",
    "    for possible_subject in doc:\n",
    "        if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "            subj = possible_subject\n",
    "            verb = possible_subject.head\n",
    "            print(subj, verb)\n",
    "            for vr in verb.rights:\n",
    "                if vr.dep == xcomp:\n",
    "                    for vc in vr.children:\n",
    "                        if vc.dep == dobj and vc.pos == NOUN:\n",
    "                            relationships.append((subj,verb,vr,vc))\n",
    "                if vr.dep == prep:\n",
    "                    for vc in vr.children:\n",
    "                        if vc.dep == pobj and vc.pos == NOUN:\n",
    "                            relationships.append((subj,verb,vr,vc)) \n",
    "                if vr.dep == dobj and vr.pos == NOUN:\n",
    "                    relationships.append((subj,verb,vr))\n",
    "                print(vr, vr.dep_,vr.pos_)\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_relationships(nlp(\"I want to buy stock.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_relationships(nlp(\"Bob said he knows about the scam.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_relationships(nlp(\"I bought stock.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_relationships(nlp(\"Jane said Bob knows about the scam.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple method for anaphora? resolution\n",
    "def find_referent(doc, pronoun, msgfrom, msgto):\n",
    "    if pronoun.text.lower() in ['i','myself','me','we']:\n",
    "        return msgfrom\n",
    "    elif pronoun.text.lower() in ['you','your']:\n",
    "        return msgto\n",
    "    else:\n",
    "        w = pronoun\n",
    "        while w.head != w:\n",
    "            w = w.head\n",
    "        for c in w.children:\n",
    "            if c.dep == nsubj:\n",
    "                return c.text\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Bob said he knows about the scam.')\n",
    "rels = extract_relationships(doc)\n",
    "for rel in rels:\n",
    "    for w in rel:\n",
    "        if w.pos == PRON:\n",
    "            print(find_referent(doc, w, 'meme','youyou'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships2(doc,msgfrom,msgto):\n",
    "    relationships = []\n",
    "    for possible_subject in doc:\n",
    "        if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "            subj = possible_subject\n",
    "            verb = possible_subject.head\n",
    "            if subj.pos == PRON or subj.pos ==PROPN:\n",
    "                if subj.pos == PRON:\n",
    "                    ref = find_referent(doc,subj,msgfrom,msgto)\n",
    "                    if ref is not None:\n",
    "                        subj = ref\n",
    "                    else:\n",
    "                        subj = subj.text\n",
    "                else:\n",
    "                    subj = subj.text\n",
    "            if subj.lower() in ['they','it']:\n",
    "                continue\n",
    "            print(subj, verb)\n",
    "            \n",
    "            for vr in verb.rights:\n",
    "                if vr.dep_ == xcomp:\n",
    "                    for vc in vr.children:\n",
    "                        if vc.dep_ == dobj and vc.pos_ == NOUN:\n",
    "                            if vr.idx < vc.idx:\n",
    "                                relationships.append((subj,verb.lemma_,vr.lemma_+\" \"+vc.lemma_))\n",
    "                            else:\n",
    "                                relationships.append((subj,verb.lemma_,vc.lemma_+\" \"+vr.lemma_))\n",
    "                elif vr.dep_ == prep:\n",
    "                    for vc in vr.children:\n",
    "                        if vc.dep_ == pobj and vc.pos_ == NOUN:\n",
    "                            relationships.append((subj,verb.lemma_,vc.lemma_)) \n",
    "                elif vr.dep_ == dobj and (vr.pos_ == NOUN or vr.pos_ == PROPN):\n",
    "                    has_compound = False\n",
    "                    for vc in vr.children:\n",
    "                        if vc.dep_ == 'compound' and vc.pos_ == NOUN:\n",
    "                            has_compound = True\n",
    "                            if vr.idx < vc.idx:\n",
    "                                relationships.append((subj,verb.lemma_,vr.lemma_+\" \"+vc.lemma_))\n",
    "                            else:\n",
    "                                relationships.append((subj,verb.lemma_,vc.lemma_+\" \"+vr.lemma_))\n",
    "                        if not has_compound:\n",
    "                            relationships.append((subj,verb.lemma_,vr.lemma_))\n",
    "                elif vr.dep_ == attr:\n",
    "                    relationships.append((subj,verb.lemma_,vr.lemma_))\n",
    "                print(vr.dep_,vr.pos_,vr.idx,vr.lemma_,relationships)\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships2(doc, msgfrom, msgto):\n",
    "    #print(doc)\n",
    "    relationships = []\n",
    "    for possible_subject in doc:\n",
    "        if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "            subj = possible_subject\n",
    "            verb = possible_subject.head\n",
    "            \n",
    "            if subj.pos == PRON or subj.pos == PROPN:\n",
    "                if subj.pos == PRON:\n",
    "                    ref = find_referent(doc, subj, msgfrom, msgto)\n",
    "                    if ref is not None:\n",
    "                        subj = ref\n",
    "                    else:\n",
    "                        subj = subj.text\n",
    "                else:\n",
    "                    subj = subj.text\n",
    "                \n",
    "                # ignore worthless subjects\n",
    "                if subj.lower() in ['they', 'it']:\n",
    "                    continue\n",
    "                    \n",
    "                for vr in verb.rights:\n",
    "                    if vr.dep == xcomp:\n",
    "                        for vc in vr.children:\n",
    "                            if vc.dep == dobj and vc.pos == NOUN:\n",
    "                                if vr.idx < vc.idx:\n",
    "                                    relationships.append((subj, verb.lemma_, vr.lemma_ + \" \" + vc.lemma_))\n",
    "                                else:\n",
    "                                    relationships.append((subj, verb.lemma_, vc.lemma_ + \" \" + vr.lemma_))\n",
    "                    elif vr.dep == prep:\n",
    "                        for vc in vr.children:\n",
    "                            if vc.dep == pobj and vc.pos == NOUN:\n",
    "                                relationships.append((subj, verb.lemma_, vc.lemma_))\n",
    "                    elif vr.dep == dobj and (vr.pos == NOUN or vr.pos == PROPN):\n",
    "                        has_compound = False\n",
    "                        for vc in vr.children:\n",
    "                            if vc.dep_ == 'compound' and vc.pos == NOUN:\n",
    "                                has_compound = True\n",
    "                                if vr.idx < vc.idx:\n",
    "                                    relationships.append((subj, verb.lemma_, vr.lemma_ + \" \" + vc.lemma_))\n",
    "                                else:\n",
    "                                    relationships.append((subj, verb.lemma_, vc.lemma_ + \" \" + vr.lemma_))\n",
    "                        if not has_compound:\n",
    "                            relationships.append((subj, verb.lemma_, vr.lemma_))\n",
    "                    elif vr.dep == attr:\n",
    "                        relationships.append((subj, verb.lemma_, vr.lemma_))\n",
    "    return relationships\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_relationships2(nlp('I want to buy stock.'),'me@example','you@example')\n",
    ",extract_relationships2(nlp('Jane said Bob knows about the scam'),'me@example','you@example')\n",
    ",extract_relationships2(nlp('Bob knows about the scam.'),'me@example','you@example')\n",
    ",extract_relationships2(nlp('You bought stock.'),'me@example','you@example'),sep =\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_relationships(mbox, msg_key):\n",
    "    message = mbox.get(msg_key)\n",
    "    if message['From'] is not None and message['To'] is not None:\n",
    "        try:\n",
    "            msgnlp = nlp(cleanup_email(message.get_payload()))\n",
    "            return extract_relationships2(msgnlp,message['From'],message['To'].split(', ')[0])\n",
    "        except :\n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_email_relationships(mbox, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph, Literal, RDF\n",
    "from rdflib.namespace import FOAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add((Literal('mark.greenberg@enron.com'),RDF.type, FOAF.Person))\n",
    "g.add((Literal('mark.greenberg@enron.com'),Literal('requested'),Literal('copy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p, o in g:\n",
    "    print(s, p, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in g.subjects(RDF.type, FOAF.Person):\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = g.query('SELECT ?s ?o where { ?s ?p ?o . }',initBindings = {'p':Literal('requested')})\n",
    "\n",
    "for row in qres:\n",
    "    print(\"%s -> %s\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_email_relationships(mbox):\n",
    "    g = Graph()\n",
    "    msg_key_idx = {}\n",
    "    msg_key_idx_reverse = {}\n",
    "    for msg_key in msgs[15000:15500]:\n",
    "        rels = extract_email_relationships(mbox, msg_key)\n",
    "        for (s, p, o) in rels:\n",
    "            r=(Literal(s),Literal(p),Literal(o))\n",
    "            g.add(r)\n",
    "            if r in msg_key_idx:\n",
    "                msg_key_idx[r].append(msg_key)\n",
    "            else:\n",
    "                msg_key_idx[r] = [msg_key]\n",
    "                \n",
    "            if msg_key in msg_key_idx_reverse:\n",
    "                msg_key_idx_reverse[msg_key].append(r)\n",
    "            else:\n",
    "                msg_key_idx_reverse[msg_key] = [r]\n",
    "    return (g, msg_key_idx, msg_key_idx_reverse)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(g, msg_key_idx,msg_key_idx_reverse) = create_graph_from_email_relationships(mbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p, o in g:\n",
    "    print((s,p,o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates = set()\n",
    "for s, p, o in g:\n",
    "    predicates.add(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = g.query('SELECT ?s ?o where { ?s ?p ?o . }',initBindings = {'p':Literal('remove')})\n",
    "\n",
    "for row in qres:\n",
    "    print(\"%s -> %s\"%row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_key_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_key_idx_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_relationships(predicate, g, msg_key_idx, msg_key_idx_reverse):\n",
    "    doc = nlp(predicate)\n",
    "    p = Literal(doc[0].lemma_)\n",
    "    qres = g.query('SELECT ?s ?o WHERE { ?s ?p ?o . }', initBindings = {'p' : p})\n",
    "\n",
    "    for row in qres:\n",
    "        r = (row[0], p, row[1])\n",
    "        print(\"%s\\t*%s*\\t%s -- msg_keys: %s\" % (row[0], p, row[1], msg_key_idx[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_email_relationships(mbox):\n",
    "    g = Graph('Sleepycat', identifier='enron_relationships') # needs python lib bsddb3\n",
    "    #installing bsddb3 has issues\n",
    "    g.open('enron_relationships.rdf', create = True)\n",
    "    msg_key_idx = {}\n",
    "    msg_key_idx_reverse = {}\n",
    "    \n",
    "    i = 0\n",
    "    msgs = mbox.keys()\n",
    "    msg_count = len(msgs)\n",
    "    for msg_key in msgs: # no limit now, do all messages\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            print(\"Message %d of %d\" % (i, msg_count))\n",
    "    \n",
    "        # find relationships\n",
    "        rels = extract_email_relationships(mbox, msg_key)\n",
    "        \n",
    "        # for each relationship\n",
    "        for (s, p, o) in rels:\n",
    "            \n",
    "            r = (Literal(s), Literal(p), Literal(o))\n",
    "            \n",
    "            # add relationship to the graph\n",
    "            g.add(r)\n",
    "            \n",
    "            # remember which message(s) had this relationship\n",
    "            if r in msg_key_idx:\n",
    "                msg_key_idx[r].append(msg_key)\n",
    "            else:\n",
    "                msg_key_idx[r] = [msg_key]\n",
    "                \n",
    "            # remember the relationships this message had\n",
    "            if msg_key in msg_key_idx_reverse:\n",
    "                msg_key_idx_reverse[msg_key].append(r)\n",
    "            else:\n",
    "                msg_key_idx_reverse[msg_key] = [r]\n",
    "                \n",
    "    return (g, msg_key_idx, msg_key_idx_reverse)\n",
    "\n",
    "(g, msg_key_idx, msg_key_idx_reverse) = create_graph_from_email_relationships(mbox)\n",
    "\n",
    "query_relationships(\"removed\", g, msg_key_idx, msg_key_idx_reverse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
